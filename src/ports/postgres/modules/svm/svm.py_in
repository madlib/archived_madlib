import plpy

from utilities.control import MinWarning
from utilities.in_mem_group_control import GroupIterationController
from utilities.validate_args import explicit_bool_to_text
from utilities.utilities import unique_string
from utilities.utilities import extract_keyvalue_params
from utilities.utilities import add_postfix
from utilities.utilities import _string_to_array_with_quotes
from utilities.utilities import _string_to_array
from utilities.utilities import _assert

from utilities.validate_args import cols_in_tbl_valid
from utilities.validate_args import input_tbl_valid
from utilities.validate_args import output_tbl_valid
from utilities.validate_args import is_var_valid
from utilities.validate_args import get_expr_type


def _compute_svm(args):
    """
    Compute SVM coefficients

    @return Number of iterations that has been run
    """
    iterationCtrl = GroupIterationController(args)
    with iterationCtrl as it:
        it.iteration = 0
        has_converged = False
        while not has_converged:
            it.update(
                """
                {schema_madlib}.linear_svm_igd_step(
                    ({col_ind_var})::FLOAT8[],
                    CASE WHEN ({col_dep_var}) IS NULL THEN NULL
                        WHEN ({col_dep_var}) = {mapped_value_for_negative} THEN FALSE
                        ELSE TRUE
                    END,
                    {rel_state}.{col_grp_state},
                    {n_features}::INT4,
                    {stepsize}::FLOAT8,
                    {lambda}::FLOAT8,
                    {is_l2}::BOOLEAN,
                    {col_n_tuples}
                    )
                """)
            it.kwargs['stepsize'] *= it.kwargs['decay_factor']
            has_converged = it.test(
                    """
                    {iteration} >= {max_iter}
                    OR {schema_madlib}.internal_linear_svm_igd_distance(
                        _state_previous, _state_current) < {tolerance}
                    """)
        it.final()
    return iterationCtrl.iteration
# ---------------------------------------------------


# Function to run the SVM classification algorithm
def svm_classification(schema_madlib, source_table, model_table,
                       dependent_varname, independent_varname,
                       kernel_func, kernel_params, grouping_col,
                       optim_params, reg_params, verbose, **kwargs):
    """
    Executes the linear support vector classification algorithm.

    """

    # verbosing
    verbosity_level = "info" if verbose else "error"
    with MinWarning(verbosity_level):
        # validate input
        input_tbl_valid(source_table, 'SVM')
        _assert(is_var_valid(source_table, dependent_varname),
                "SVM error: invalid dependent_varname ('" + str(dependent_varname) +
                "') for source_table (" + source_table + ")!")
        _assert(is_var_valid(source_table, independent_varname),
                "SVM error: invalid independent_varname ('" + str(independent_varname) +
                "') for source_table (" + source_table + ")!")

        # map dependent variables
        dep_labels=plpy.execute("""
                SELECT {dependent_varname} AS y
                FROM {source_table}
                WHERE ({dependent_varname}) IS NOT NULL
                GROUP BY ({dependent_varname})
                ORDER BY ({dependent_varname})
            """.format(**locals()))
        _dep_var_mapping = ["'" + d['y'] + "'" if isinstance(d['y'], basestring)
                            else str(d['y']) for d in dep_labels]
        if len(_dep_var_mapping) != 2:
            plpy.error("SVM error: Only binary classification is supported. "
                       "Found more than two dependent variable values ({0})".
                       format(str(_dep_var_mapping)))
        dep_type = get_expr_type(dependent_varname, source_table)
        if '[]' in dep_type:
            plpy.error("SVM error: dependent_varname cannot be of array type!")

        # output
        output_tbl_valid(model_table, 'SVM')
        summary_table = add_postfix(model_table, "_summary")
        output_tbl_valid(summary_table, 'SVM')

        # arguments for iterating
        if grouping_col:
            grouping_list = [i + "::text"
                             for i in explicit_bool_to_text(
                                source_table,
                                _string_to_array_with_quotes(grouping_col),
                                schema_madlib)]
            grouping_str = ','.join(grouping_list)
        else:
            grouping_str = "Null"
        grouping_str1 = "" if not grouping_col else grouping_col + ","
        grouping_str2 = "1 = 1" if not grouping_col else grouping_col

        n_features = plpy.execute("SELECT array_upper({0}, 1) AS dim "
                                  "FROM {1} LIMIT 1".
                                  format(independent_varname, source_table)
                                  )[0]['dim']
        args = {'rel_args': unique_string(),
                'rel_state': unique_string(),
                'rel_source': source_table,
                'col_ind_var': independent_varname,
                'col_dep_var': dependent_varname,
                'col_grp_iteration': unique_string(),
                'col_grp_state': unique_string(),
                'col_n_tuples': unique_string(),
                'mapped_value_for_negative': _dep_var_mapping[0],
                'stateType': "double precision[]"}
        args.update(locals())

        # other params
        kernel_func = 'linear' if not kernel_func else kernel_func.lower()
        # Add non-linear kernels below after implementing them.
        supported_kernels = ['linear']
        try:
            # allow user to specify a prefix substring of
            # supported kernel function names. This works because the supported
            # kernel functions have unique prefixes.
            kernel_func = next(x for x in supported_kernels if x.startswith(kernel_func))
        except StopIteration:
            # next() returns a StopIteration if no element found
            plpy.error("SVM Error: Invalid kernel function: {0}. Supported kernel functions are ({1})"
                       .format(kernel_func, ','.join(sorted(supported_kernels))))

        if grouping_col:
            cols_in_tbl_valid(source_table, _string_to_array_with_quotes(grouping_col), 'SVM')
            intersect = frozenset(_string_to_array(grouping_col)).intersection(
                                    frozenset(
                                        ('coef', '__random_feature_data',
                                         '__random_feature_data', 'loss'
                                         'num_rows_processed', 'num_rows_skipped',
                                         'norm_of_gradient', 'num_iterations')))
            if len(intersect) > 0:
                plpy.error("SVM error: Conflicting grouping column name.\n"
                           "Some predefined keyword(s) ({0}) are not allowed!".format(
                                ', '.join(intersect)))

        optim_params_dict = _extract_optim_params(schema_madlib, optim_params)
        reg_params_dict = _extract_reg_params(schema_madlib, reg_params)
        args.update(optim_params_dict)
        args.update(reg_params_dict),
        args['stepsize'] = args['init_stepsize']
        args['is_l2'] = True if args['norm'] == 'l2' else False

        # place holder for compatibility
        plpy.execute("CREATE TABLE pg_temp.{rel_args} AS SELECT 1".format(**args))
        # actual iterative algorithm computation
        n_iters_run = _compute_svm(args)

        # organizing results
        args['mapping'] = _dep_var_mapping[0] + "," + _dep_var_mapping[1]
        groupby_str = "GROUP BY {grouping_col}, {col_grp_key}".format(**args) if grouping_col else ""
        using_str = "USING ({col_grp_key})".format(**args) if grouping_col else "ON TRUE"
        plpy.execute("""
                CREATE TABLE {model_table} AS
                SELECT
                    {grouping_str1}
                    (result).coefficients           AS coef,
                    (result).loss                   AS loss,
                    (result).norm_of_gradient       AS norm_of_gradient,
                    {n_iters_run}                   AS num_iterations,
                    (result).num_rows_processed     AS num_rows_processed,
                    n_tuples_including_nulls - (result).num_rows_processed
                                                    AS num_rows_skipped,
                    NULL                            AS __random_feature_data,
                    ARRAY[{mapping}]::{dep_type}[]  AS _dep_var_mapping
                FROM (
                    SELECT
                        {schema_madlib}.internal_linear_svm_igd_result(
                            {col_grp_state}
                        ) AS result,
                        {col_grp_key}
                    FROM {rel_state}
                    WHERE {col_grp_iteration} = {n_iters_run}
                ) rel_state_subq
                JOIN (
                    SELECT
                        {grouping_str1}
                        count(*) AS n_tuples_including_nulls,
                        array_to_string(ARRAY[{grouping_str}],
                                        ','
                                       ) AS {col_grp_key}
                    FROM {source_table}
                    {groupby_str}
                ) n_tuples_including_nulls_subq
                {using_str}
                """.format(n_iters_run=n_iters_run,
                           groupby_str=groupby_str,
                           using_str=using_str, **args))

        if type(args['lambda']) is list:
            args['lambda_str'] = '{' + ','.join(str(e) for e in args['lambda']) + '}'
        else:
            args['lambda_str'] = str(args['lambda'])
        plpy.execute("""
                CREATE TABLE {summary_table} AS
                SELECT
                    'svm'::text                         AS method,
                    '__MADLIB_VERSION__'::text          AS version_number,
                    '{source_table}'::text              AS source_table,
                    '{model_table}'::text               AS model_table,
                    '{dependent_varname}'::text         AS dependent_varname,
                    '{independent_varname}'::text       AS independent_varname,
                    'linear'::text                      AS kernel_func,
                    NULL::text                          AS kernel_params,
                    '{grouping_col}'::text              AS grouping_col,
                    'init_stepsize={init_stepsize}, ' ||
                    'decay_factor={decay_factor}, ' ||
                    'max_iter={max_iter}, ' ||
                    'tolerance={tolerance}'::text       AS optim_params,
                    'lambda={lambda_str}, ' ||
                    'norm={norm}, ' ||
                    'n_folds={n_folds}'::text           AS reg_params,
                    count(*)::integer                   AS num_all_groups,
                    0::integer                          AS num_failed_groups,
                    sum(num_rows_processed)::bigint     AS total_rows_processed,
                    sum(num_rows_skipped)::bigint       AS total_rows_skipped
                FROM {model_table};
                """.format(**args))
# ------------------------------------------------------------------------------


def svm_predict(schema_madlib, model_table, new_data_table, id_col_name,
                output_table, **kwargs):
    """
    Scores the data points stored in a table using a learned support vector model.

    @param model_table Name of learned model
    @param new_data_table Name of table/view containing the data points to be scored
    @param id_col_name Name of column in source_table containing (integer) identifier for data point
    @param output_table Name of table to store the results
    """
    # suppress warnings
    with MinWarning("error"):
        # model table
        input_tbl_valid(model_table, 'SVM')
        cols_in_tbl_valid(model_table, ['coef'], 'SVM')
        # summary table
        summary_table = add_postfix(model_table, "_summary")
        input_tbl_valid(summary_table, 'SVM')
        cols_in_tbl_valid(summary_table,
                          ['dependent_varname', 'independent_varname', 'kernel_func',
                           'kernel_params', 'grouping_col'], 'SVM')

        # read necessary info from summary
        summary = plpy.execute("""
                SELECT
                    dependent_varname,
                    independent_varname,
                    kernel_func,
                    kernel_params,
                    grouping_col
                FROM {summary_table}
                """.format(**locals()))[0]
        dependent_varname = summary['dependent_varname']
        independent_varname = summary['independent_varname']
        kernel_func = summary['kernel_func']
        kernel_params = summary['kernel_params']
        grouping_col = summary['grouping_col']

        input_tbl_valid(new_data_table, 'SVM')
        _assert(is_var_valid(new_data_table, dependent_varname),
                "SVM error: dependent_varname ('" + dependent_varname +
                "') is invalid for new_data_table (" + new_data_table + ")!")
        _assert(is_var_valid(new_data_table, independent_varname),
                "SVM error: independent_varname ('" + independent_varname +
                "') is invalid for new_data_table (" + new_data_table + ")!")
        if id_col_name is None:
            plpy.error("SVM error: id_col_name is NULL!")
        _assert(is_var_valid(new_data_table, id_col_name),
                "SVM error: id_col_name ('" + id_col_name +
                "') is invalid for new_data_table (" + new_data_table + ")!")
        output_tbl_valid(output_table, 'SVM')

        if grouping_col != "NULL":
            sql = """
            CREATE TABLE {output_table} AS
            SELECT
                {id_col_name} AS id,
                CASE WHEN {schema_madlib}.array_dot(coef, {independent_varname}) >= 0
                    THEN _dep_var_mapping[2]
                    ELSE _dep_var_mapping[1]
                END AS prediction,
                {model_table}.{grouping_col} as grouping_col
            FROM {model_table}
            JOIN {new_data_table}
            ON {model_table}.{grouping_col} = {new_data_table}.{grouping_col}
            WHERE not {schema_madlib}.array_contains_null({independent_varname})
            ORDER BY grouping_col, id
            """.format(**locals())
        else:
            sql="""
            CREATE TABLE {output_table} AS
            SELECT
                {id_col_name} AS id,
                CASE WHEN {schema_madlib}.array_dot(coef, {independent_varname}) >= 0
                    THEN _dep_var_mapping[2]
                    ELSE _dep_var_mapping[1]
                END AS prediction
            FROM {model_table}, {new_data_table}
            WHERE not {schema_madlib}.array_contains_null({independent_varname})
            """.format(**locals())

        plpy.execute(sql)


def _extract_optim_params(schema_madlib, optim_params, module='SVM'):
    default_dict = dict(init_stepsize=0.01, decay_factor=0.9, max_iter=100, tolerance=1e-3)
    optim_params_types = dict(init_stepsize=float, decay_factor=float, max_iter=int, tolerance=float)
    optim_params_dict = extract_keyvalue_params(optim_params,
                                                optim_params_types,
                                                default_dict)

    if optim_params_dict['init_stepsize'] <= 0:
        plpy.error("{0} error: init_stepsize must be positive!".format(module))
    if optim_params_dict['decay_factor'] <= 0 or optim_params_dict['decay_factor'] > 1:
        plpy.error("{0} error: decay_factor must be in (0,1]!".format(module))
    if optim_params_dict['max_iter'] <= 0:
        plpy.error("{0} error: max_iter must be positive!".format(module))
    if optim_params_dict['tolerance'] < 0:
        plpy.error("{0} error: tolerance must be non-negative!".format(module))

    return optim_params_dict


def _extract_reg_params(schema_madlib, reg_params, module='SVM'):
    default_dict = {'lambda': 0.01, 'norm': 'L2', 'n_folds': 0}
    reg_params_types_lambda_scalar = {'lambda': float, 'norm': str, 'n_folds': int}
    reg_params_types_lambda_list = {'lambda': list, 'norm': str, 'n_folds': int}
    try:
        reg_params_dict = extract_keyvalue_params(reg_params,
                                                  reg_params_types_lambda_scalar,
                                                  default_dict)
        is_lambda_list = False
    except ValueError:
        reg_params_dict = extract_keyvalue_params(reg_params,
                                                  reg_params_types_lambda_list,
                                                  default_dict)
        is_lambda_list = True

    if reg_params_dict['n_folds'] < 0:
        plpy.error("{0} error: n_folds must be non-negative!".format(module))
    # FIXME
    if reg_params_dict['n_folds'] > 1:
        plpy.error("{0} error: cross-validation not implemented!".format(module))

    # validate lambda
    if not is_lambda_list and reg_params_dict['lambda'] < 0:
        plpy.error("{0} error: lambda must be non-negative!".format(module))
    if is_lambda_list:
        if len(reg_params_dict['lambda']) != 1:
            plpy.error("{0} error: lambda must be a scalar or of length 1 when n_folds is 0 or 1".format(module))
        # good for only not CV
        reg_params_dict['lambda'] = reg_params_dict['lambda'][0]
        if reg_params_dict['lambda'] < 0:
            plpy.error("{0} error: lambda must be non-negative!".format(module))

    reg_params_dict['norm'] = reg_params_dict['norm'].lower()
    if reg_params_dict['norm'] != 'l1' and reg_params_dict['norm'] != 'l2':
        plpy.error("{0} error: norm must be either L1 or L2!".format(module))

    return reg_params_dict
