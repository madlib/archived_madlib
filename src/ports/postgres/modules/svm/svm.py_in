import plpy

from utilities.control import MinWarning
from utilities.in_mem_group_control import GroupIterationController
from utilities.validate_args import explicit_bool_to_text
from utilities.utilities import unique_string
from utilities.utilities import extract_keyvalue_params
from utilities.utilities import add_postfix
from utilities.utilities import _string_to_array_with_quotes
from utilities.utilities import _string_to_array
from utilities.utilities import _assert

from utilities.validate_args import cols_in_tbl_valid
from utilities.validate_args import input_tbl_valid
from utilities.validate_args import output_tbl_valid
from utilities.validate_args import is_var_valid
from utilities.validate_args import get_expr_type


def _compute_svm(args):
    """
    Compute SVM coefficients

    @return Number of iterations that has been run
    """
    iterationCtrl = GroupIterationController(args)
    with iterationCtrl as it:
        it.iteration = 0
        has_converged = False
        while not has_converged:
            it.update(
                """
                {schema_madlib}.linear_svm_igd_step(
                    ({col_ind_var})::FLOAT8[],
                    ({col_dep_var_trans})::FLOAT8,
                    {rel_state}.{col_grp_state},
                    {n_features}::INT4,
                    {stepsize}::FLOAT8,
                    {lambda}::FLOAT8,
                    {is_l2}::BOOLEAN,
                    {col_n_tuples},
                    ({select_epsilon})::FLOAT8,
                    {is_svc}::BOOLEAN
                    )
                """)
            it.info()
            if it.kwargs['decay_factor'] > 0:
                it.kwargs['stepsize'] = it.kwargs['stepsize'] * it.kwargs['decay_factor']
            else:
                it.kwargs['stepsize'] = it.kwargs['init_stepsize'] / (it.iteration + 1)
            has_converged = it.test(
                    """
                    {iteration} >= {max_iter}
                    OR {schema_madlib}.internal_linear_svm_igd_distance(
                        _state_previous, _state_current) < {tolerance}
                    """)
        it.final()
    return iterationCtrl.iteration
# ---------------------------------------------------


def svm(schema_madlib, source_table, model_table,
        dependent_varname, independent_varname, kernel_func,
        kernel_params, grouping_col, params, is_svc,
        verbose, **kwargs):
    """
    Executes the linear support vector classification algorithm.
    """
    # verbosing
    verbosity_level = "info" if verbose else "error"
    with MinWarning(verbosity_level):
        # validate input
        input_tbl_valid(source_table, 'SVM')
        _assert(is_var_valid(source_table, dependent_varname),
                "SVM error: invalid dependent_varname ('" + str(dependent_varname) +
                "') for source_table (" + source_table + ")!")
        _assert(is_var_valid(source_table, independent_varname),
                "SVM error: invalid independent_varname ('" + str(independent_varname) +
                "') for source_table (" + source_table + ")!")

        dep_type = get_expr_type(dependent_varname, source_table)
        if '[]' in dep_type:
            plpy.error("SVM error: dependent_varname cannot be of array type!")

        # validate output tables
        output_tbl_valid(model_table, 'SVM')
        summary_table = add_postfix(model_table, "_summary")
        output_tbl_valid(summary_table, 'SVM')

        # arguments for iterating
        n_features = plpy.execute("SELECT array_upper({0}, 1) AS dim "
                                  "FROM {1} LIMIT 1".
                                  format(independent_varname, source_table)
                                  )[0]['dim']
        if grouping_col:
            grouping_list = [i + "::text"
                             for i in explicit_bool_to_text(
                                source_table,
                                _string_to_array_with_quotes(grouping_col),
                                schema_madlib)]
            grouping_str = ','.join(grouping_list)
        else:
            grouping_str = "Null"
        grouping_str1 = "" if not grouping_col else grouping_col + ","
        grouping_str2 = "1 = 1" if not grouping_col else grouping_col

        args = {
                'rel_args': unique_string(desp='rel_args'),
                'rel_state': unique_string(desp='rel_state'),
                'col_grp_iteration': unique_string(desp='col_grp_iteration'),
                'col_grp_state': unique_string(desp='col_grp_state'),
                'col_grp_key': unique_string(desp='col_grp_key'),
                'col_n_tuples': unique_string(desp='col_n_tuples'),
                'state_type': "double precision[]",
                'rel_source': source_table,
                'col_ind_var': independent_varname,
                'col_dep_var': dependent_varname}
        args.update(locals())
        # variables defined above cannot be moved below this line
        # -------------------------------------------------------

        # other params
        kernel_func = 'linear' if not kernel_func else kernel_func.lower()
        # Add non-linear kernels below after implementing them.
        supported_kernels = ['linear']
        try:
            # allow user to specify a prefix substring of
            # supported kernel function names. This works because the supported
            # kernel functions have unique prefixes.
            kernel_func = next(x for x in supported_kernels if x.startswith(kernel_func))
        except StopIteration:
            # next() returns a StopIteration if no element found
            plpy.error("SVM Error: Invalid kernel function: {0}. "
                       "Supported kernel functions are ({1})"
                       .format(kernel_func, ','.join(sorted(supported_kernels))))

        if grouping_col:
            cols_in_tbl_valid(source_table, _string_to_array_with_quotes(grouping_col), 'SVM')
            intersect = frozenset(_string_to_array(grouping_col)).intersection(
                                    frozenset(
                                        ('coef', '__random_feature_data',
                                         '__random_feature_data', 'loss'
                                         'num_rows_processed', 'num_rows_skipped',
                                         'norm_of_gradient', 'num_iterations')))
            if len(intersect) > 0:
                plpy.error("SVM error: Conflicting grouping column name.\n"
                           "Some predefined keyword(s) ({0}) are not allowed!".format(
                                ', '.join(intersect)))

        args.update(_extract_params(schema_madlib, params))
        args.update(_process_epsilon(is_svc, args))

        if not is_svc:
            # transform col_dep_var to binary (1 or -1) if classification
            args.update({
                    'col_dep_var_trans': dependent_varname,
                    'mapping': 'NULL',
                    'method': 'SVR'})
        else:
            # dependent variable mapping
            dep_labels=plpy.execute("""
                SELECT {dependent_varname} AS y
                FROM {source_table}
                WHERE ({dependent_varname}) IS NOT NULL
                GROUP BY ({dependent_varname})
                ORDER BY ({dependent_varname})""".format(**locals()))
            dep_var_mapping = ["'" + d['y'] + "'" if isinstance(d['y'], basestring)
                               else str(d['y']) for d in dep_labels]
            if len(dep_var_mapping) != 2:
                plpy.error("SVM error: Classification currently only supports binary output")

            col_dep_var_trans = (
                """
                CASE WHEN ({col_dep_var}) IS NULL THEN NULL
                    WHEN ({col_dep_var}) = {mapped_value_for_negative} THEN -1.0
                    ELSE 1.0
                END
                """
                .format(col_dep_var=dependent_varname,
                        mapped_value_for_negative=dep_var_mapping[0])
                )

            args.update({
                 'mapped_value_for_negative': dep_var_mapping[0],
                 'col_dep_var_trans': col_dep_var_trans,
                 'mapping': dep_var_mapping[0] + "," + dep_var_mapping[1],
                 'method': 'SVC'})

        args['stepsize'] = args['init_stepsize']
        args['is_l2'] = True if args['norm'] == 'l2' else False

        # place holder for compatibility
        plpy.execute("CREATE TABLE pg_temp.{0} AS SELECT 1".format(args['rel_args']))
        # actual iterative algorithm computation
        n_iters_run = _compute_svm(args)

        # organizing results
        groupby_str = "GROUP BY {grouping_col}, {col_grp_key}".format(**args) if grouping_col else ""
        using_str = "USING ({col_grp_key})".format(**args) if grouping_col else "ON TRUE"
        model_table_query = """
            CREATE TABLE {model_table} AS
                SELECT
                    {grouping_str1}
                    (result).coefficients           AS coef,
                    (result).loss                   AS loss,
                    (result).norm_of_gradient       AS norm_of_gradient,
                    {n_iters_run}                   AS num_iterations,
                    (result).num_rows_processed     AS num_rows_processed,
                    n_tuples_including_nulls - (result).num_rows_processed
                                                    AS num_rows_skipped,
                    NULL                            AS __random_feature_data,
                    ARRAY[{mapping}]::{dep_type}[]  AS dep_var_mapping
                FROM
                (
                    SELECT
                        {schema_madlib}.internal_linear_svm_igd_result(
                            {col_grp_state}
                        ) AS result,
                        {col_grp_key}
                    FROM {rel_state}
                    WHERE {col_grp_iteration} = {n_iters_run}
                ) rel_state_subq
                JOIN
                (
                    SELECT
                        {grouping_str1}
                        count(*) AS n_tuples_including_nulls,
                        array_to_string(ARRAY[{grouping_str}],
                                        ','
                                       ) AS {col_grp_key}
                    FROM {source_table}
                    {groupby_str}
                ) n_tuples_including_nulls_subq
                {using_str}
            """.format(n_iters_run=n_iters_run,
                       groupby_str=groupby_str,
                       using_str=using_str, **args)
        plpy.execute(model_table_query)

        if isinstance(args['lambda'], list):
            args['lambda_str'] = '{' + ','.join(str(e) for e in args['lambda']) + '}'
        else:
            args['lambda_str'] = str(args['lambda'])

        plpy.execute("""
                CREATE TABLE {summary_table} AS
                SELECT
                    '{method}'::text                    AS method,
                    '__MADLIB_VERSION__'::text          AS version_number,
                    '{source_table}'::text              AS source_table,
                    '{model_table}'::text               AS model_table,
                    '{dependent_varname}'::text         AS dependent_varname,
                    '{independent_varname}'::text       AS independent_varname,
                    'linear'::text                      AS kernel_func,
                    NULL::text                          AS kernel_params,
                    '{grouping_text}'::text             AS grouping_col,
                    'init_stepsize={init_stepsize}, '   ||
                        'decay_factor={decay_factor}, ' ||
                        'max_iter={max_iter}, '         ||
                        'tolerance={tolerance}'::text   AS optim_params,
                    'lambda={lambda_str}, ' ||
                        'norm={norm}, '     ||
                        'n_folds={n_folds}'::text       AS reg_params,
                    count(*)::integer                   AS num_all_groups,
                    0::integer                          AS num_failed_groups,
                    sum(num_rows_processed)::bigint     AS total_rows_processed,
                    sum(num_rows_skipped)::bigint       AS total_rows_skipped,
                    '{epsilon}'::double precision       AS epsilon,
                    '{eps_table}'::text                 AS eps_table
                FROM {model_table};
                """.format(grouping_text="NULL" if not grouping_col else grouping_col,
                           **args))
# ------------------------------------------------------------------------------


def svm_predict(schema_madlib, model_table, new_data_table, id_col_name,
                output_table, **kwargs):
    """
    Scores the data points stored in a table using a learned support vector model.

    @param model_table Name of learned model
    @param new_data_table Name of table/view containing the data points to be scored
    @param id_col_name Name of column in source_table containing (integer) identifier for data point
    @param output_table Name of table to store the results
    """
    # suppress warnings
    with MinWarning("warning"):
        # model table
        input_tbl_valid(model_table, 'SVM')
        cols_in_tbl_valid(model_table, ['coef'], 'SVM')
        # summary table
        summary_table = add_postfix(model_table, "_summary")
        input_tbl_valid(summary_table, 'SVM')
        cols_in_tbl_valid(summary_table,
                          ['dependent_varname', 'independent_varname', 'kernel_func',
                           'kernel_params', 'grouping_col'], 'SVM')

        # read necessary info from summary
        summary = plpy.execute("""
                SELECT
                    method,
                    dependent_varname,
                    independent_varname,
                    kernel_func,
                    kernel_params,
                    grouping_col
                FROM {summary_table}
                """.format(**locals()))[0]
        method = summary['method']
        dependent_varname = summary['dependent_varname']
        independent_varname = summary['independent_varname']
        kernel_func = summary['kernel_func']
        kernel_params = summary['kernel_params']
        grouping_col = summary['grouping_col']

        input_tbl_valid(new_data_table, 'SVM')
        _assert(is_var_valid(new_data_table, dependent_varname),
                "SVM error: dependent_varname ('" + dependent_varname +
                "') is invalid for new_data_table (" + new_data_table + ")!")
        _assert(is_var_valid(new_data_table, independent_varname),
                "SVM error: independent_varname ('" + independent_varname +
                "') is invalid for new_data_table (" + new_data_table + ")!")
        _assert(id_col_name is not None, "SVM error: id_col_name is NULL!")
        _assert(is_var_valid(new_data_table, id_col_name),
                "SVM error: id_col_name ('" + id_col_name +
                "') is invalid for new_data_table (" + new_data_table + ")!")
        output_tbl_valid(output_table, 'SVM')
        if method.upper() == 'SVC':
            pred_query = """
                        CASE WHEN {schema_madlib}.array_dot(
                                coef::double precision [],
                                {independent_varname}::double precision []) >= 0
                            THEN dep_var_mapping[2]
                            ELSE dep_var_mapping[1]
                        END
                        """.format(schema_madlib=schema_madlib,
                                   independent_varname=independent_varname)
        elif method.upper() == 'SVR':
            pred_query = """
                        {schema_madlib}.array_dot(
                                coef::double precision [],
                                {independent_varname}::double precision [])
                        """.format(schema_madlib=schema_madlib,
                                   independent_varname=independent_varname)
        else:
            plpy.error("SVM error: Invalid 'method' value in summary table. "
                       "'method' can only be SVC or SVR!")

        if grouping_col != "NULL":
            sql = """
            CREATE TABLE {output_table} AS
            SELECT
                {id_col_name} AS id,
                {pred_query} AS prediction,
                {model_table}.{grouping_col} as grouping_col
            FROM
                {model_table}
                    JOIN
                {new_data_table}
                    ON {model_table}.{grouping_col} = {new_data_table}.{grouping_col}
            WHERE
                not {schema_madlib}.array_contains_null({independent_varname})
            ORDER BY
                grouping_col, id
            """.format(**locals())
        else:
            sql="""
            CREATE TABLE {output_table} AS
            SELECT
                {id_col_name} AS id,
                {pred_query} as prediction
            FROM
                {model_table},
                {new_data_table}
            WHERE
                not {schema_madlib}.array_contains_null({independent_varname})
            """.format(**locals())
        plpy.execute(sql)


def _process_epsilon(is_svc, args):
    eps_table = args['eps_table']
    grouping_col = args['grouping_col']
    grouping_str = args['grouping_str']
    col_grp_key = args['col_grp_key']
    rel_source = args['rel_source']
    rel_epsilon = ''
    select_epsilon = ''
    as_rel_source = '_src'

    epsilon = args['epsilon']
    if is_svc or not grouping_col or not eps_table:
        if eps_table:
            plpy.warning('SVM: ignoring the input epsilon table!')
        select_epsilon = str(epsilon)
    else:
        rel_epsilon = unique_string(desp='rel_epsilon')
        input_tbl_valid(eps_table, 'SVM')
        _assert(is_var_valid(eps_table, grouping_col),
                "SVM error: invalid column names ('" + str(grouping_col) +
                "') for eps_table (" + eps_table + ")!")
        plpy.execute("""
            DROP TABLE IF EXISTS {rel_epsilon};
            CREATE TEMPORARY TABLE {rel_epsilon} AS (
                    SELECT
                        {col_grp_key},
                        coalesce(epsilon, {epsilon}) AS epsilon
                    FROM
                    (
                        SELECT array_to_string(ARRAY[{grouping_str}], ',') AS
                                {col_grp_key}
                        FROM {rel_source}
                        GROUP BY {grouping_col}
                    ) q1
                    LEFT JOIN
                    (
                        SELECT array_to_string(ARRAY[{grouping_str}], ',') AS
                                {col_grp_key},
                               epsilon
                        FROM {eps_table}
                    ) q2
                    USING ({col_grp_key})
            );
            """.format(**locals()))

        select_epsilon = """SELECT epsilon
                            FROM
                                {rel_epsilon}
                            WHERE
                                {rel_epsilon}.{col_grp_key} = {as_rel_source}.{col_grp_key}
            """.format(rel_epsilon=rel_epsilon, as_rel_source=as_rel_source,
                       col_grp_key=col_grp_key)

    return {'select_epsilon': select_epsilon,
            'epsilon': epsilon,
            'rel_epsilon': rel_epsilon,
            'as_rel_source': as_rel_source}


def _extract_params(schema_madlib, params, module='SVM'):
    # NOTICE: the type of values in params_default should be consistent with
    # the types specified in params_types
    params_default = {'init_stepsize': 0.01,
                      'decay_factor': 0.9,
                      'max_iter': 100,
                      'tolerance': 1e-10,
                      'lambda': 1.0,
                      'norm': 'L2',
                      'n_folds': 0,
                      'epsilon': 0.01,
                      'eps_table': ''}

    params_types = {'init_stepsize': float,
                    'decay_factor': float,
                    'max_iter': int,
                    'tolerance': float,
                    'lambda': list,
                    'norm': str,
                    'n_folds': int,
                    'epsilon': float,
                    'eps_table': str}

    params_vals = extract_keyvalue_params(params,
                                          params_types,
                                          params_default)

    if params_vals['n_folds'] < 0:
        plpy.error("SVM error: n_folds must be non-negative")
    # FIXME
    _assert(params_vals['n_folds'] <= 1,
            "SVM error: cross-validation has not been implemented")

    # validate lambda
    if hasattr(params_vals['lambda'], '__len__'):
        # this check should be removed after cross validation is added
        if len(params_vals['lambda']) != 1:
            plpy.error("{0} error: lambda must be a scalar or of length 1 when n_folds is 0 or 1".format(module))
        params_vals['lambda'] = params_vals['lambda'][0]
    _assert(params_vals['lambda'] >= 0,
            "SVM error: lambda must be non-negative!")
    params_vals['norm'] = params_vals['norm'].lower()
    _assert(params_vals['norm'] == 'l1' or params_vals['norm'] == 'l2',
            "SVM error: norm must be either L1 or L2")
    _assert(params_vals['init_stepsize'] > 0,
            "SVM error: init_stepsize must be positive")
    _assert(params_vals['decay_factor'] <= 1,
            "SVM error: decay_factor must be <= 1")
    _assert(params_vals['max_iter'] > 0,
            "SVM error: max_iter must be positive")
    _assert(params_vals['tolerance'] >= 0,
            "SVM error: tolerance must be non-negative")
    _assert(params_vals['epsilon'] >= 0,
            "SVM error: epsilon cannot be less than 0")
    return params_vals
