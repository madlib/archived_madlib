from __future__ import division

import plpy

from utilities.control import MinWarning
from utilities.in_mem_group_control import GroupIterationController
from utilities.validate_args import explicit_bool_to_text
from utilities.utilities import unique_string
from utilities.utilities import extract_keyvalue_params
from utilities.utilities import add_postfix
from utilities.utilities import _string_to_array_with_quotes
from utilities.utilities import _string_to_array
from utilities.utilities import _assert
from utilities.utilities import num_features

from utilities.validate_args import cols_in_tbl_valid
from utilities.validate_args import input_tbl_valid
from utilities.validate_args import output_tbl_valid
from utilities.validate_args import is_var_valid
from utilities.validate_args import get_expr_type

from validation.internal.cross_validation import CrossValidator
from .kernel_approximation import createKernel, loadKernel


def _compute_svm(args):
    """
    Compute SVM coefficients

    @return Number of iterations that has been run
    """
    init_stepsize = args['init_stepsize']
    args['stepsize'] = init_stepsize
    iterationCtrl = GroupIterationController(args)
    with iterationCtrl as it:
        it.iteration = 0
        has_converged = False
        while not has_converged:
            it.update(
                """
                {schema_madlib}.linear_svm_igd_step(
                    ({col_ind_var})::FLOAT8[],
                    ({col_dep_var_trans})::FLOAT8,
                    {rel_state}.{col_grp_state},
                    {n_features}::INT4,
                    {stepsize}::FLOAT8,
                    {lambda}::FLOAT8,
                    {is_l2}::BOOLEAN,
                    {col_n_tuples},
                    ({select_epsilon})::FLOAT8,
                    {is_svc}::BOOLEAN
                    )
                """)
            it.info()
            if it.kwargs['decay_factor'] > 0:
                it.kwargs['stepsize'] *= it.kwargs['decay_factor']
            else:
                it.kwargs['stepsize'] = init_stepsize / (it.iteration + 1)
            has_converged = it.test(
                """
                {iteration} >= {max_iter}
                OR {schema_madlib}.internal_linear_svm_igd_distance(
                    _state_previous, _state_current) < {tolerance}
                """)
        it.final()
    return iterationCtrl.iteration
# ---------------------------------------------------


def _verify_table(source_table, model_table, dependent_varname,
                  independent_varname, **kwargs):
    # validate input
    input_tbl_valid(source_table, 'SVM')
    _assert(is_var_valid(source_table, dependent_varname),
            "SVM error: invalid dependent_varname "
            "('{dependent_varname}') for source_table "
            "({source_table})!".format(dependent_varname=dependent_varname,
                                       source_table=source_table))
    _assert(is_var_valid(source_table, independent_varname),
            "SVM error: invalid independent_varname "
            "('{independent_varname}') for source_table "
            "({source_table})!".format(independent_varname=independent_varname,
                                       source_table=source_table))

    dep_type = get_expr_type(dependent_varname, source_table)
    if '[]' in dep_type:
        plpy.error("SVM error: dependent_varname cannot be of array type!")

    # validate output tables
    output_tbl_valid(model_table, 'SVM')
    summary_table = add_postfix(model_table, "_summary")
    output_tbl_valid(summary_table, 'SVM')


def _verify_grouping(schema_madlib, source_table, grouping_col):
    if grouping_col and grouping_col.lower() != 'null':
        cols_in_tbl_valid(source_table,
                          _string_to_array_with_quotes(grouping_col),
                          'SVM')
        intersect = frozenset(
            _string_to_array(grouping_col)).intersection(
                frozenset(
                    ('coef', 'random_feature_data',
                     'random_feature_data', 'loss'
                     'num_rows_processed', 'num_rows_skipped',
                     'norm_of_gradient', 'num_iterations')))
        _assert(len(intersect) == 0,
                "SVM error: Conflicting grouping column name.\n"
                "Some predefined keyword(s) ({0}) are not allowed "
                "for grouping column names!".format(', '.join(intersect)))

        grouping_list = [i + "::text"
                         for i in explicit_bool_to_text(
                             source_table,
                             _string_to_array_with_quotes(grouping_col),
                             schema_madlib)]
        grouping_str = ','.join(grouping_list)
    else:
        grouping_str = "Null"
        grouping_col = None

    return grouping_str, grouping_col


def _verify_params_dict(params_dict):
    _assert(not hasattr(params_dict['lambda'], '__len__'),
            "SVM Error: lambda should not be a list after cross validation!")
    _assert(not hasattr(params_dict['epsilon'], '__len__'),
            "SVM Error: epsilon should not be a list after cross validation!")
    _assert(not hasattr(params_dict['init_stepsize'], '__len__'),
            "SVM Error: init_stepsize should not be a "
            "list after cross validation!")
    _assert(not hasattr(params_dict['decay_factor'], '__len__'),
            "SVM Error: decay_factor should not be a "
            "list after cross validation!")
    _assert(not hasattr(params_dict['max_iter'], '__len__'),
            "SVM Error: max_iter should not be a list after cross validation!")
    return params_dict


def _build_output_tables(n_iters_run, model_table, args, transformer,**kwargs):
    if transformer is None:
        dependent_varname = args['col_dep_var']
        independent_varname = args['col_ind_var']
        source_table = args['rel_source']
        kernel_func = "linear"
        kernel_params = "NULL"
    else:
        original_table = transformer.original_table
        dependent_varname = original_table['dependent_varname']
        independent_varname = original_table['independent_varname']
        source_table = original_table['source_table']
        random_table = add_postfix(model_table, "_random")
        transformer.saveAs(random_table)
        kernel_func = transformer.kernel_func
        kernel_params = transformer.kernel_params

    grouping_col = args['grouping_col']
    col_grp_key = args['col_grp_key']
    groupby_str, grouping_str1, using_str = "", "", "ON TRUE"
    if grouping_col:
        groupby_str = "GROUP BY {grouping_col}, {col_grp_key}".format(
            grouping_col=grouping_col, col_grp_key=col_grp_key)
        grouping_str1 = grouping_col + ","
        using_str = "USING ({col_grp_key})".format(col_grp_key=col_grp_key)
    # organizing results
    dep_type = get_expr_type(dependent_varname, source_table)
    model_table_query = """
        CREATE TABLE {model_table} AS
            SELECT
                {grouping_str1}
                (result).coefficients           AS coef,
                (result).loss                   AS loss,
                (result).norm_of_gradient       AS norm_of_gradient,
                {n_iters_run}                   AS num_iterations,
                (result).num_rows_processed     AS num_rows_processed,
                n_tuples_including_nulls - (result).num_rows_processed
                                                AS num_rows_skipped,
                ARRAY[{mapping}]::{dep_type}[]  AS dep_var_mapping
            FROM
            (
                SELECT
                    {schema_madlib}.internal_linear_svm_igd_result(
                        {col_grp_state}
                    ) AS result,
                    {col_grp_key}
                FROM {rel_state}
                WHERE {col_grp_iteration} = {n_iters_run}
            ) rel_state_subq
            JOIN
            (
                SELECT
                    {grouping_str1}
                    count(*) AS n_tuples_including_nulls,
                    array_to_string(ARRAY[{grouping_str}],
                                    ','
                                   ) AS {col_grp_key}
                FROM {source_table}
                {groupby_str}
            ) n_tuples_including_nulls_subq
            {using_str}
        """.format(n_iters_run=n_iters_run,
                   groupby_str=groupby_str,
                   grouping_str1=grouping_str1,
                   using_str=using_str,
                   source_table=source_table,
                   model_table=model_table,
                   dep_type=dep_type, **args)
    plpy.execute(model_table_query)

    args['lambda_str'] = str(args['lambda'])
    summary_table = add_postfix(model_table, "_summary")
    grouping_text = "NULL" if not grouping_col else grouping_col
    plpy.execute("""
            CREATE TABLE {summary_table} AS
            SELECT
                '{method}'::text                    AS method,
                '__MADLIB_VERSION__'::text          AS version_number,
                '{source_table}'::text              AS source_table,
                '{model_table}'::text               AS model_table,
                '{dependent_varname}'::text         AS dependent_varname,
                '{independent_varname}'::text       AS independent_varname,
                '{kernel_func}'::text               AS kernel_func,
                '{kernel_params}'::text             AS kernel_params,
                '{grouping_text}'::text             AS grouping_col,
                'init_stepsize={init_stepsize}, '   ||
                    'decay_factor={decay_factor}, ' ||
                    'max_iter={max_iter}, '         ||
                    'tolerance={tolerance}'::text   AS optim_params,
                'lambda={lambda_str}, ' ||
                    'norm={norm}, '     ||
                    'n_folds={n_folds}'::text       AS reg_params,
                count(*)::integer                   AS num_all_groups,
                0::integer                          AS num_failed_groups,
                sum(num_rows_processed)::bigint     AS total_rows_processed,
                sum(num_rows_skipped)::bigint       AS total_rows_skipped,
                '{epsilon}'::double precision       AS epsilon,
                '{eps_table}'::text                 AS eps_table
            FROM {model_table};
            """.format(grouping_text=grouping_text,
                       summary_table=summary_table,
                       source_table=source_table,
                       model_table=model_table,
                       kernel_func=kernel_func,
                       kernel_params=kernel_params,
                       dependent_varname=dependent_varname,
                       independent_varname=independent_varname,
                       **args))


def svm_help(schema_madlib, message, is_svc, **kwargs):
    method = 'svm_classification' if is_svc else 'svm_regression'

    args = dict(schema_madlib=schema_madlib, method=method)

    summary = """
    ----------------------------------------------------------------
                            SUMMARY
    ----------------------------------------------------------------
    Support Vector Machines (SVMs) are models for regression
    and classification tasks.

    SVM models have two particularly desirable features:
    robustness in the presence of noisy data and applicability
    to a variety of data configurations.

    For more details on function usage:
        SELECT {schema_madlib}.{method}('usage')
        """.format(**args)

    usage = """
    ---------------------------------------------------------------------------
                                    USAGE
    ---------------------------------------------------------------------------
    SELECT {schema_madlib}.{method}(
        source_table,         -- name of input table
        model_table,          -- name of output model table
        dependent_varname,    -- name of dependent variable
        independent_varname,  -- names of independent variables
        kernel_func,          -- optional, default: 'linear'.
                                 supported type of kernel: 'linear', 'gaussian',
                                 and 'polynomial'
        kernel_params,        -- optional, default: NULL
                                 parameters for non-linear kernel in a
                                 comma-separated string of key-value pairs. The
                                 parameters differ depending on the value of
                                 kernel_func.
                                 to find out more:

                                    SELECT {schema_madlib}.{method}('kernel_func')

                                 where replace 'kernel_func' with whatever kernel
                                 you are interested in, i.e.,

                                    SELECT {schema_madlib}.{method}('gaussian')

        grouping_cols,        -- optional, default NULL
                                 names of columns to group-by
        params,               -- optional, default NULL
                                 parameters for optimization and regularization in
                                 a comma-separated string of key-value pairs. If a
                                 list of values are provided, then cross-
                                 validation will be performed to select the best
                                 value from the list.
                                 to find out more:

                                    SELECT {schema_madlib}.{method}('params')

        verbose               -- optional, default FALSE
                                 whether to print useful info
    );


    ---------------------------------------------------------------------------
                                    OUTPUT
    ---------------------------------------------------------------------------
    The model table produced by svm contains the following columns:

    coef                FLOAT8,     -- vector of the coefficients.
    grouping_key        TEXT,       -- identifies the group to which
                                       the datum belongs.
    num_rows_processed  BIGINT,     -- numbers of rows processed.
    num_rows_skipped    BIGINT,     -- numbers of rows skipped due
                                       to missing values or failures.
    num_iterations      INTEGER,    -- number of iterations completed by
                                       the optimization algorithm.
                                       The algorithm either converged in this
                                       number of iterations or hit the maximum
                                       number specified in the
                                       optimization parameters.
    __dep_var_mapping   TEXT[],     -- vector of dependendent variable labels.
                                       The first entry will correspond to -1
                                       and the second to +1, for internal use.

    An auxiliary table named <model_table>_random is created if the kernel is not
    linear. It contains data needed to embed test data into random feature space
    (see reference [2,3]). This data is used internally by svm_predict and not
    meaningful on its own.

    A summary table named <model_table>_summary is also created at the same time,
    which has the following columns:
    method                  varchar,    -- 'svm'
    version_number          varchar,    -- version of madlib which was used to
                                           generate the model.
    source_table            varchar,    -- the data source table name.
    model_table             varchar,    -- the model table name.
    dependent_varname       varchar,    -- the dependent variable.
    independent_varname     varchar,    -- the independent variables.
    kernel_func             varchar,    -- the kernel function.
    kernel_parameters       varchar,    -- the kernel parameters.
    grouping_col            varchar,    -- columns on which to group.
    optim_params            varchar,    -- a string containing the
                                           optimization parameters.
    reg_params              varchar,    -- a string containing the
                                           regularization parameters.
    num_all_groups          integer,    -- number of groups in glm training.
    num_failed_groups       integer,    -- number of failed groups in glm training.
    total_rows_processed    integer,    -- total numbers of rows processed
                                           in all groups.
    total_rows_skipped      integer,    -- numbers of rows skipped in all groups
                                           due to missing values or failures.
    """.format(**args)

    params_usage = """
    ---------------------------------------------------------------------------
                                OTHER PARAMETERS
    ---------------------------------------------------------------------------
    Parameters are supplied in params argument as a string
    containing a comma-delimited list of name-value pairs.

    Hyperparameter optimization can be carried out through
    the built-in cross validation mechanism

    init_stepsize       -- Default: [0.01]. Also known as the inital learning rate.
    decay_factor        -- Default: [0.9].
                           Control the learning rate schedule:
                           0 means constant rate; -1 means inverse scaling, i.e.,
                           stepsize = init_stepsize / iteration;
                           > 0 means exponential decay, i.e.,
                           stepsize = init_stepsize * decay_factor^iteration.
    max_iter            -- Default: [100].
                           The maximum number of iterations allowed.
    tolerance           -- Default: 1e-10. The criteria to end iterations.
    lambda              -- Default: [0.01]. Regularization parameter, positive.
    norm                -- Default: 'L2'.
                           Name of the regularization, either 'L2' or 'L1'.
    epsilon             -- Default: [0.01].
                           Determines the $\epsilon$ for $\epsilon$-regression.
                           Ignored during classification.
    eps_tabl            -- Default: NULL.
                           Name of the table that contains values of epsilon for
                           different groups. Ignored when grouping_col is NULL.
    validation_result   -- Default: NULL.
                           Name of the table to store the cross validation results
                           including the values of parameters and
                           their averaged error values.
    n_folds             -- Default: 0. Number of folds.
                           Must be at least 2 to activate cross validation.
    """

    gaussian_usage = """
    ---------------------------------------------------------------------------
                                GAUSSIAN PARAMETERS
    ---------------------------------------------------------------------------
    Parameters are supplied in kernel_params argument as a string
    containing a comma-delimited list of name-value pairs.

    gamma               -- Default: 1/num_features.
                           The parameter $\gamma$ in the Radius Basis
                           Function kernel,
    n_components        -- Default: 2*num_features.
                           The dimensionality of the transformed feature space.
    random_state        -- Default: 1. Seed used by the random number generator.
    """

    poly_usage = """
    ---------------------------------------------------------------------------
                                POLYNOMIAL PARAMETERS
    ---------------------------------------------------------------------------
    Parameters are supplied in kernel_params argument as a string
    containing a comma-delimited list of name-value pairs.

    coef0               -- Default: 1.0.
                           The independent term q in (xTy + q)^r.
                           Must be larger or equal to 0. When it is 0,
                           the polynomial kernel is in homogeneous form.
    degree              -- Default: 3.
                           The parameter r in (xTy + q)^r.
    n_components        -- Default: 2*num_features.
                           The dimensionality of the transformed feature space.
                           A larger value lowers the variance of the estimate of
                           kernel but requires more memory and
                           takes longer to train.
    random_state        -- Default: 1. Seed used by the random number generator.
    """

    if not message:
        return summary
    elif message.lower() in ('usage', 'help', '?'):
        return usage
    elif message.lower() == 'params':
        return params_usage
    elif message.lower() == 'gaussian':
        return gaussian_usage
    elif message.lower() == 'polynomial':
        return poly_usage
    else:
        return """
            No such option. Use "SELECT {schema_madlib}.{method}()" for help.
        """.format(**args)


def svm(schema_madlib, source_table, model_table,
        dependent_varname, independent_varname, kernel_func,
        kernel_params, grouping_col, params, is_svc,
        verbose, **kwargs):
    """
    Executes the linear support vector classification algorithm.
    """
    # verbosing
    verbosity_level = "info" if verbose else "error"
    with MinWarning(verbosity_level):
        _verify_table(source_table,
                      model_table,
                      dependent_varname,
                      independent_varname)
        grouping_str, grouping_col = _verify_grouping(schema_madlib,
                              source_table, grouping_col)
        kernel_func = _verify_kernel(kernel_func)
        transformer = _random_feature_map(schema_madlib, source_table,
                            dependent_varname, independent_varname,
                            kernel_func, kernel_params, grouping_col)
        params_dict = _extract_params(schema_madlib, params)
        args = locals()
        if transformer is not None:
            args.update(transformer.transformed_table)
        _cross_validate_svm(args)
        _svm_parsed_params(**args)


def _cross_validate_svm(args):
    # updating params_dict will also update args['params_dict']
    params_dict = args['params_dict']

    if params_dict['n_folds'] > 1 and args['grouping_col']:
        plpy.error('SVM Error: cross validation '
                   'with grouping is not supported!')

    cv_params = {}
    if len(params_dict['lambda']) > 1:
        cv_params['lambda'] = params_dict['lambda']
    else:
        params_dict['lambda'] = params_dict['lambda'][0]
    if len(params_dict['epsilon']) > 1 and not args['is_svc']:
        cv_params['epsilon'] = params_dict['epsilon']
    else:
        params_dict['epsilon'] = params_dict['epsilon'][0]
    if len(params_dict['init_stepsize']) > 1:
        cv_params['init_stepsize'] = params_dict['init_stepsize']
    else:
        params_dict['init_stepsize'] = params_dict['init_stepsize'][0]
    if len(params_dict['max_iter']) > 1:
        cv_params['max_iter'] = params_dict['max_iter']
    else:
        params_dict['max_iter'] = params_dict['max_iter'][0]
    if len(params_dict['decay_factor']) > 1:
        cv_params['decay_factor'] = params_dict['decay_factor']
    else:
        params_dict['decay_factor'] = params_dict['decay_factor'][0]

    if not cv_params and params_dict['n_folds'] <= 1:
        # no cross validation
        return

    if cv_params and params_dict['n_folds'] <= 1:
        plpy.error("SVM Error: All parameters must be scalar "
                   "or of length 1 when n_folds is 0 or 1")

    if not cv_params and params_dict['n_folds'] > 1:
        plpy.warning('SVM Warning: n_folds > 1 but no cross validate params provided'
                     'Ignoring cross validation request.')
        return

    scorer = 'classification' if args['is_svc'] else 'regression'
    sub_args = {'params_dict': cv_params}
    transformer = args.get('transformer', None)
    # we want svm in cross validation to behave as if transformer is None
    # if it is not, then svm_predict will transform the test data again,
    # which will not be correct since test data in cross validation
    # comes from training data which has already been transformed
    args.update(dict(transformer=None))
    cv = CrossValidator(_svm_parsed_params, svm_predict, scorer, args)
    val_res = cv.validate(sub_args, params_dict['n_folds']).sorted()
    val_res.output_tbl(params_dict['validation_result'])
    params_dict.update(val_res.first('sub_args')['params_dict'])
    args.update(dict(transformer=transformer))


def _verify_kernel(kernel_func):
    kernel_func = 'linear' if not kernel_func else kernel_func.lower()
    # Add non-linear kernels below after implementing them.
    supported_kernels = ['linear', 'gaussian']
    try:
        # allow user to specify a prefix substring of
        # supported kernel function names. This works because the supported
        # kernel functions have unique prefixes.
        kernel_func = next(x for x in supported_kernels
                           if x.startswith(kernel_func))
    except StopIteration:
        # next() returns a StopIteration if no element found
        plpy.error("SVM Error: Invalid kernel function: "
                   "{0}. Supported kernel functions are ({1})"
                   .format(kernel_func, ','.join(sorted(supported_kernels))))
    return kernel_func


def _random_feature_map(schema_madlib, source_table, dependent_varname,
                        independent_varname, kernel_func,
                        kernel_params, grouping_col):
    if kernel_func == 'linear':
        return None

    n_features = num_features(source_table, independent_varname)
    transformer = createKernel(schema_madlib, n_features,
                               kernel_func, kernel_params)
    return (transformer.fit(n_features)
            .transform(source_table, independent_varname,
                       dependent_varname, grouping_col))


def _svm_parsed_params(schema_madlib, source_table, model_table,
                       dependent_varname, independent_varname, transformer,
                       grouping_str, grouping_col, params_dict, is_svc,
                       verbose, **kwargs):
    """
    Executes the linear support vector algorithm.
    """
    n_features = num_features(source_table, independent_varname)

    args = {
        'rel_args': unique_string(desp='rel_args'),
        'rel_state': unique_string(desp='rel_state'),
        'col_grp_iteration': unique_string(desp='col_grp_iteration'),
        'col_grp_state': unique_string(desp='col_grp_state'),
        'col_grp_key': unique_string(desp='col_grp_key'),
        'col_n_tuples': unique_string(desp='col_n_tuples'),
        'state_type': "double precision[]",
        'n_features': n_features,
        'verbose': verbose,
        'is_svc': is_svc,
        'schema_madlib': schema_madlib,
        'grouping_str': grouping_str,
        'grouping_col': grouping_col,
        'rel_source': source_table,
        'col_ind_var': independent_varname,
        'col_dep_var': dependent_varname}

    args.update(_verify_params_dict(params_dict))
    args.update(_process_epsilon(is_svc, args))
    args.update(_svc_or_svr(is_svc, source_table, dependent_varname))

    # place holder for compatibility
    plpy.execute("CREATE TABLE pg_temp.{0} AS SELECT 1"
                 .format(args['rel_args']))
    # actual iterative algorithm computation
    n_iters_run = _compute_svm(args)
    _build_output_tables(n_iters_run, model_table,
                         args, transformer, **kwargs)


def svm_predict(schema_madlib, model_table, new_data_table, id_col_name,
                output_table, **kwargs):
    """ Scores the data points stored in a table using a
        learned support vector model.

    @param model_table Name of learned model
    @param new_data_table Name of table/view containing the data
        points to be scored
    @param id_col_name Name of column in source_table containing
        (integer) identifier for data point
    @param output_table Name of table to store the results
    """
    # suppress warnings
    with MinWarning("warning"):
        # model table
        input_tbl_valid(model_table, 'SVM')
        cols_in_tbl_valid(model_table, ['coef'], 'SVM')
        # summary table
        summary_table = add_postfix(model_table, "_summary")
        input_tbl_valid(summary_table, 'SVM')
        cols_in_tbl_valid(summary_table,
                          ['dependent_varname', 'independent_varname',
                           'kernel_func', 'kernel_params', 'grouping_col'],
                          'SVM')

        # read necessary info from summary
        summary = plpy.execute("""
                SELECT
                    method,
                    dependent_varname,
                    independent_varname,
                    kernel_func,
                    kernel_params,
                    grouping_col
                FROM {summary_table}
                """.format(**locals()))[0]
        method = summary['method']
        dependent_varname = summary['dependent_varname']
        independent_varname = summary['independent_varname']
        kernel_func = summary['kernel_func']
        kernel_params = summary['kernel_params']
        grouping_col = summary['grouping_col']
        grouping_col = None if grouping_col == 'NULL' else grouping_col

        input_tbl_valid(new_data_table, 'SVM')
        grouping_str, grouping_col = _verify_grouping(schema_madlib,
                                                      new_data_table,
                                                      grouping_col)
        _assert(is_var_valid(new_data_table, independent_varname),
                "SVM Error: independent_varname ('" + independent_varname +
                "') is invalid for new_data_table (" + new_data_table + ")!")
        _assert(id_col_name is not None, "SVM Error: id_col_name is NULL!")
        _assert(is_var_valid(new_data_table, id_col_name),
                "SVM Error: id_col_name ('" + id_col_name +
                "') is invalid for new_data_table (" + new_data_table + ")!")
        output_tbl_valid(output_table, 'SVM')

        if kernel_func.lower() != 'linear':
            random_table = add_postfix(model_table, '_random')
            input_tbl_valid(random_table, 'SVM')
            transformer = loadKernel(schema_madlib,
                                     random_table,
                                     kernel_func,
                                     kernel_params)
            transformer.transform(new_data_table,
                                  independent_varname,
                                  grouping_col=grouping_col,
                                  id_col=id_col_name)
            transformed_table = transformer.transformed_table
            new_data_table = transformed_table['source_table']
            independent_varname = transformed_table['independent_varname']
            dependent_varname = transformed_table['dependent_varname']

        if method.upper() == 'SVC':
            pred_query = """
                        CASE WHEN {schema_madlib}.array_dot(
                                    coef::double precision [],
                                    {independent_varname}::double precision []
                                ) >= 0
                            THEN dep_var_mapping[2]
                            ELSE dep_var_mapping[1]
                        END
                        """.format(schema_madlib=schema_madlib,
                                   independent_varname=independent_varname)
        elif method.upper() == 'SVR':
            pred_query = """
                        {schema_madlib}.array_dot(
                                coef::double precision [],
                                {independent_varname}::double precision [])
                        """.format(schema_madlib=schema_madlib,
                                   independent_varname=independent_varname)
        else:
            plpy.error("SVM Error: Invalid 'method' value in summary table. "
                       "'method' can only be SVC or SVR!")

        if grouping_col:
            sql = """
            CREATE TABLE {output_table} AS
            SELECT
                {id_col_name} AS {id_col_name},
                {pred_query} AS prediction,
                ARRAY[{grouping_str}] as grouping_col,
                {grouping_col}
            FROM {model_table}
            JOIN {new_data_table}
            USING ({grouping_col})
            WHERE not {schema_madlib}.array_contains_null({independent_varname})
            ORDER BY grouping_col, {id_col_name}
            """.format(**locals())
        else:
            sql = """
            CREATE TABLE {output_table} AS
            SELECT
                {id_col_name} AS {id_col_name},
                {pred_query} as prediction
            FROM
                {model_table},
                {new_data_table}
            WHERE
                not {schema_madlib}.array_contains_null({independent_varname})
            """.format(**locals())
        plpy.execute(sql)


def _svc_or_svr(is_svc, source_table, dependent_varname):
    # transform col_dep_var to binary (1`or -1) if classification
    _args = {'col_dep_var_trans': dependent_varname,
             'mapping': 'NULL',
             'method': 'SVR'}

    if is_svc:
        # dependent variable mapping
        dep_labels = plpy.execute("""
            SELECT {dependent_varname} AS y
            FROM {source_table}
            WHERE ({dependent_varname}) IS NOT NULL
            GROUP BY ({dependent_varname})
            ORDER BY ({dependent_varname})
            """.format(source_table=source_table,
                       dependent_varname=dependent_varname))

        dep_var_mapping = ["'{0}'".format(d['y'])
                           if isinstance(d['y'], basestring)
                           else str(d['y']) for d in dep_labels]

        _assert(len(dep_var_mapping) == 2,
                "SVM Error: Classification currently "
                "only supports binary output!")

        col_dep_var_trans = (
            """
            CASE WHEN ({col_dep_var}) IS NULL THEN NULL
                WHEN ({col_dep_var}) = {mapped_value_for_negative} THEN -1.0
                ELSE 1.0
            END
            """
            .format(col_dep_var=dependent_varname,
                    mapped_value_for_negative=dep_var_mapping[0])
            )

        _args.update({
            'mapped_value_for_negative': dep_var_mapping[0],
            'col_dep_var_trans': col_dep_var_trans,
            'mapping': dep_var_mapping[0] + "," + dep_var_mapping[1],
            'method': 'SVC'})

    return _args


def _process_epsilon(is_svc, args):
    eps_table = args['eps_table']
    grouping_col = args['grouping_col']
    grouping_str = args['grouping_str']
    col_grp_key = args['col_grp_key']
    rel_source = args['rel_source']
    epsilon = args['epsilon']
    rel_epsilon = ''
    select_epsilon = '{0}'.format(epsilon)
    as_rel_source = '_src'

    if not is_svc and grouping_col and eps_table:
        rel_epsilon = unique_string(desp='rel_epsilon')
        input_tbl_valid(eps_table, 'SVM')
        _assert(is_var_valid(eps_table, grouping_col),
                "SVM Error: invalid column names ('{grouping_col}') "
                "for eps_table ('{eps_table}')!"
                .format(grouping_col=grouping_col,
                        eps_table=eps_table))
        plpy.execute("""
            DROP TABLE IF EXISTS {rel_epsilon};
            CREATE TEMPORARY TABLE {rel_epsilon} AS (
                    SELECT
                        {col_grp_key},
                        coalesce(epsilon, {epsilon}) AS epsilon
                    FROM (
                        SELECT
                            array_to_string(ARRAY[{grouping_str}], ',') AS
                                {col_grp_key}
                        FROM
                            {rel_source}
                        GROUP BY {grouping_col}
                    ) q1
                    LEFT JOIN
                    (
                        SELECT
                            array_to_string(ARRAY[{grouping_str}], ',') AS
                                {col_grp_key},
                               epsilon
                        FROM {eps_table}
                    ) q2
                    USING ({col_grp_key})
            );
            """.format(rel_epsilon=rel_epsilon,
                       col_grp_key=col_grp_key,
                       epsilon=epsilon,
                       grouping_str=grouping_str,
                       rel_source=rel_source,
                       grouping_col=grouping_col,
                       eps_table=eps_table))

        select_epsilon = (
            """
            (
                SELECT epsilon
                FROM
                    {rel_epsilon}
                WHERE
                    {rel_epsilon}.{col_grp_key} = {as_rel_source}.{col_grp_key}
            )
            """
            .format(rel_epsilon=rel_epsilon,
                    as_rel_source=as_rel_source,
                    col_grp_key=col_grp_key))

    return {'select_epsilon': select_epsilon,
            'epsilon': epsilon,
            'rel_epsilon': rel_epsilon,
            'as_rel_source': as_rel_source}


def _extract_params(schema_madlib, params, module='SVM'):
    # NOTICE: the type of values in params_default should be consistent with
    # the types specified in params_types
    params_default = {
        'init_stepsize': [0.01],
        'decay_factor': [0.9],
        'max_iter': [100],
        'tolerance': 1e-10,
        'lambda': [0.01],
        'norm': 'L2',
        'n_folds': 0,
        'validation_result': '',
        'epsilon': [0.01],
        'eps_table': ''}

    params_types = {
        'init_stepsize': list,
        'decay_factor': list,
        'max_iter': list,
        'tolerance': float,
        'lambda': list,
        'norm': str,
        'n_folds': int,
        'validation_result': str,
        'epsilon': list,
        'eps_table': str}

    params_vals = extract_keyvalue_params(params,
                                          params_types,
                                          params_default)
    if params_vals['n_folds'] < 0:
        plpy.error("{0} Error: n_folds must be non-negative!".format(module))

    # validate lambda
    params_vals['lambda'] = map(float, params_vals['lambda'])
    _assert(all(lmd >= 0 for lmd in params_vals['lambda']),
            "{0} Error: lambda must be non-negative!".format(module))
    # validate epsilon
    params_vals['epsilon'] = map(float, params_vals['epsilon'])
    _assert(all(e >= 0 for e in params_vals['epsilon']),
            "{0} Error: epsilon must be non-negative!".format(module))
    # validating cross validation is delegated to _cross_validate_svm()
    params_vals['init_stepsize'] = map(float, params_vals['init_stepsize'])
    _assert(all(e > 0 for e in params_vals['init_stepsize']),
            "{0} Error: init_stepsize must be positive!".format(module))
    params_vals['max_iter'] = map(int, params_vals['max_iter'])
    _assert(all(e > 0 for e in params_vals['max_iter']),
            "{0} Error: max_iter must be positive!".format(module))
    params_vals['decay_factor'] = map(float, params_vals['decay_factor'])
    _assert(all(e <= 1 for e in params_vals['decay_factor']),
            "{0} Error: decay_factor must be <= 1!".format(module))

    if params_vals['validation_result']:
        output_tbl_valid(params_vals['validation_result'], 'SVM')

    params_vals['norm'] = params_vals['norm'].lower()
    _assert(params_vals['norm'] == 'l1' or params_vals['norm'] == 'l2',
            "{0} Error: norm must be either L1 or L2!".format(module))
    _assert(params_vals['tolerance'] >= 0,
            "{0} error: tolerance must be non-negative!".format(module))

    params_vals['is_l2'] = True if params_vals['norm'] == 'l2' else False
    return params_vals
