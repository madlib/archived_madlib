/* ----------------------------------------------------------------------- *//**
 *
 * @file train_data_loader.sql_in
 *
 * @brief create all the necessary tables to store the training data, then use the linear chain conditional 
 *        random field to train the data
 * @param datapath the path to the crf training data
 * @date May 2012
 * @sa For an introduction to the text feature extraction, see the module
 *     description \ref grp_crf
 *
 *//* ----------------------------------------------------------------------- */

m4_include(`SQLCommon.m4')
CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.load_crf_trainingdata(datapath text) RETURNS void AS
$$      
        query = "DROP TABLE IF EXISTS MADLIB_SCHEMA.textfex_feature;" + \
                "CREATE TABLE MADLIB_SCHEMA.textfex_feature (id integer,name text,prev_label_id integer,label_id integer,weight float)";
        plpy.execute(query);

        plpy.execute("CREATE TEMP TABLE temp_feature(name text,prev_label_id integer,label_id integer);)

	# label space
	query = "DROP TABLE IF EXISTS MADLIB_SCHEMA.textfex_label CASCADE;" + \
	        "CREATE TABLE MADLIB_SCHEMA.textfex_label (id integer,label character varying)";
	plpy.execute(query);

        # regex table
	query = "DROP TABLE IF EXISTS MADLIB_SCHEMA.textfex_regex;" + \
                "CREATE TABLE MADLIB_SCHEMA.textfex_regex (pattern text,name text)";
	plpy.execute(query);
    
        # import training data to the database
        query = "DROP TABLE IF EXISTS MADLIB_SCHEMA.textfex_segmenttbl CASCADE;" + \
                "CREATE TABLE MADLIB_SCHEMA.textfex_segmenttbl (start_pos integer,doc_id integer,seg_text text, label character varying,max_pos integer)";
        plpy.execute(query);

        # CRF features
        query = "DROP TABLE IF EXISTS MADLIB_SCHEMA.textfex_dictionary;" + \
                "CREATE TABLE MADLIB_SCHEMA.textfex_dictionary (token text,token_id integer,label text,count integer,total integer)";
        plpy.execute(query);

	query = "COPY MADLIB_SCHEMA.textfex_segmenttbl (start_pos,doc_id,seg_text,lable,max_pos) FROM '" + datapath + "/enron-segmenttbl.tab'";
        plpy.execute(query);

        # insert into dictionary table
        plpy.execute("""INSERT INTO textfex_dictionary(text,token_id,label,count,total)
                        SELECT DISTINCT seg_text
                        FROM   """ + textfex_segmentbl
                        GROUP BY seg_tex, label""";""")
 
        # create a temporary table to store all the features
        
        # extract all the edge features
        INSERT INTO temp_feature(name,pre_label_id,label_id) 
        SELECT 'E.', seg1.label, seg2.label 
        FROM   textfex_segmenttbl seg1, textfex_segment seg2
        WHERE  seg1.doc_id = seg2.doc_id AND seg1.start_pos+1 = seg2.start_pos   
         
        #extract all the regex features
        INSERT INTO temp_feature(name,pre_label_id,label_id)
        SELECT 'R_' || name, -1, label
        FROM   textfex_regex, textfex_segmenttbl
        WHERE  seg_text ~ pattern        
           
        #extract all the start feature
        INSERT INTO temp_feature(name,pre_label_id,label_id)
        SELECT 'S.', -1, label
        FROM   textfex_segmenttbl
        WHERE  start_pos = 0;
        
        #extract all the end featue
        INSERT INTO temp_feature(name,pre_label_id,label_id)
        SELECT 'End.', -1, label
        FROM   textfex_segmenttbl
        WHERE  start_pos = max_pos;

        #word feature
        INSERT INTO temp_feature(name,pre_label_id,label_id)
        SELECT 'W_' || seg_text, -1, label
        FROM   textfex_segmenttbl;
        
        #unknown feature
        INSERT INTO temp_feature(name,pre_label_id,label_id)
        SELECT 'U', -1, label
        FROM   textfex_segmenttbl;
        WHERE seg_text 
