#!/usr/bin/env python

import plpy

# -----------------------------------------------
# Function to run the regression algorithm
# -----------------------------------------------
def svm_regression( input_table, model_table, parallel, eta = 0.1, nu = 0.005, slambda = 0.2):
    """
    Executes the support vector regression algorithm.

    @param input_table Name of table/view containing the training data
    @param model_table Name of table under which we want to store the learned model 
    @param parallel A flag indicating whether the system should learn multiple models in parallel
    @param eta Learning rate in (0,1] (default value is 0.1)
    @param nu  Compression parameter in (0,1] associated with the fraction of training data that will become support vectors (default value is 0.005)
    @param slambda Regularisation parameter (default value is 0.2)
    
    """

    # Output error if model_table already exist
    # if __check_rel_exist(model_table):
    #    plpy.error('Table ' + model_table + ' exists; please use a different model table or drop ' + model_table + ' before calling this function.');

    # plpy.execute('drop table if exists ' + model_table);
    plpy.execute('create table ' + model_table + ' ( id text, weight float8, sv float8[] ) ifdef(`GREENPLUM', `distributed randomly')'); 

    plpy.execute('create temp table svm_temp_result ( id text, model MADLIB_SCHEMA.svm_model_rec ) ifdef(`GREENPLUM', `distributed randomly')');

    plpy.info("Parameters:");
    plpy.info(" * input_table = %s" % input_table);
    plpy.info(" * model_table = " + model_table);
    plpy.info(" * parallel = " + str(parallel));
    plpy.info(" * eta = " + str(eta));
    plpy.info(" * nu = " + str(nu));
    plpy.info(" * slambda = " + str(slambda));

    if (parallel) :
        # Learning multiple models in parallel  

        # Start learning process
        sql = 'insert into svm_temp_result (select \'' + model_table + '\' || gp_segment_id, MADLIB_SCHEMA.svm_reg_agg(ind, label,' + str(eta) + ',' + str(nu) + ',' + str(slambda) + ') from ' + input_table + ' group by gp_segment_id)';
        plpy.execute(sql);

        # Store the models learned
        numproc_t = plpy.execute('select count(distinct(gp_segment_id)) from ' + input_table);
        numproc = numproc_t[0]['count'];
        plpy.execute('select MADLIB_SCHEMA.svm_store_model(\'svm_temp_result\', \'' + model_table + '\',\'' + model_table + '\', ' + str(numproc) + ')');     

    else :
        # Learning a single model

        # Start learning process    
        sql = 'insert into svm_temp_result (select \'' + model_table + '\', MADLIB_SCHEMA.svm_reg_agg(ind, label,' + str(eta) + ',' + str(nu) + ',' + str(slambda) + ') from ' + input_table + ')';
        plpy.execute(sql);
        # Store the model learned
        plpy.execute('select MADLIB_SCHEMA.svm_store_model(\'svm_temp_result\', \'' + model_table + '\', \'' + model_table + '\')');

    # Retrieve and return the summary for each model learned    
    if parallel:
        where_cond = "position('" + model_table + "' in id) > 0 AND '" + model_table + "' <> id";
    else:
        where_cond = "id = '" + model_table + "'";

    summary = plpy.execute("select id, (model).inds, (model).cum_err, (model).epsilon, (model).b, (model).nsvs from svm_temp_result where " + where_cond);

    result = [];
    for i in range(0,summary.nrows()):
        result = result + [(model_table, summary[i]['id'], summary[i]['inds'], summary[i]['cum_err'], summary[i]['epsilon'], summary[i]['b'], summary[i]['nsvs'])];

    # Clean up temp storage of models
    plpy.execute('drop table svm_temp_result'); 

    return result;

# -----------------------------------------------
# Function to run the classification algorithm
# -----------------------------------------------
def svm_classification( input_table, model_table, parallel, eta=0.1, nu=0.005):
    """
    Executes the support vector classification algorithm.

    @param input_table Name of table/view containing the training data
    @param model_table Name under which we want to store the learned model 
    @param parallel A flag indicating whether the system should learn multiple models in parallel
    @param eta Learning rate in (0,1] (default value is 0.1)
    @param nu Compression parameter in (0,1] associated with the fraction of training data that will become support vectors (default value is 0.005)
    
    """

    # Output error if model_table already exist
    # if __check_rel_exist(model_table):
    #    plpy.error('Table ' + model_table + ' exists; please use a different model table or drop ' + model_table + ' before calling this function.');

    # plpy.execute('drop table if exists ' + model_table);
    plpy.execute('create table ' + model_table + ' ( id text, weight float8, sv float8[] ) ifdef(`GREENPLUM', `distributed randomly')'); 

    plpy.execute('create temp table svm_temp_result ( id text, model MADLIB_SCHEMA.svm_model_rec ) ifdef(`GREENPLUM', `distributed randomly')');

    plpy.info("Parameters:");
    plpy.info(" * input_table = " + input_table);
    plpy.info(" * model_table = " + model_table);
    plpy.info(" * parallel = " + str(parallel));
    plpy.info(" * eta = " + str(eta));
    plpy.info(" * nu = " + str(nu));

    if (parallel) :
        # Learning multiple models in parallel  

        # Start learning process
        sql = 'insert into svm_temp_result (select \'' + model_table + '\' || gp_segment_id, MADLIB_SCHEMA.svm_cls_agg(ind, label,' + str(eta) + ',' + str(nu) + ') from ' + input_table + ' group by gp_segment_id)';
        plpy.execute(sql);

        # Store the models learned
        numproc_t = plpy.execute('select count(distinct(gp_segment_id)) from ' + input_table);
        numproc = numproc_t[0]['count'];
        plpy.execute('select MADLIB_SCHEMA.svm_store_model(\'svm_temp_result\', \'' + model_table + '\',\'' + model_table + '\', ' + str(numproc) + ')');

    else :
        # Learning a single model

        # Start learning process    
        sql = 'insert into svm_temp_result (select \'' + model_table + '\', MADLIB_SCHEMA.svm_cls_agg(ind, label,' + str(eta) + ',' + str(nu) + ') from ' + input_table + ')';
        plpy.execute(sql);

        # Store the model learned
        plpy.execute('select MADLIB_SCHEMA.svm_store_model(\'svm_temp_result\', \'' + model_table + '\', \'' + model_table + '\')');

    # Retrieve and return the summary for each model learned    
    if parallel:
        where_cond = "position('" + model_table + "' in id) > 0 AND '" + model_table + "' <> id";
    else:
        where_cond = "id = '" + model_table + "'";

    summary = plpy.execute("select id, (model).inds, (model).cum_err, (model).rho, (model).b, (model).nsvs from svm_temp_result where " + where_cond);

    result = [];
    for i in range(0,summary.nrows()):
        result = result + [(model_table, summary[i]['id'], summary[i]['inds'], summary[i]['cum_err'], summary[i]['rho'], summary[i]['b'], summary[i]['nsvs'])];

    # Clean up temp storage of models
    plpy.execute('drop table svm_temp_result');

    return result;

# -----------------------------------------------
# Function to run the novelty detection algorithm
# -----------------------------------------------
def svm_novelty_detection( input_table, model_table, parallel, eta = 0.1, nu = 0.01):
    """
    Executes the support vector novelty detection algorithm.

    @param input_table Name of table/view containing the training data
    @param model_table Name of table under which we want to store the learned model 
    @param parallel A flag indicating whether the system should learn multiple models in parallel.
    @param eta Learning rate in (0,1] (default value is 0.1)
    @param nu Compression parameter in (0,1] associated with the fraction of training data that will become support vectors (default value is 0.01)
    """

    # Output error if model_table already exist
    # if __check_rel_exist(model_table):
    #    plpy.error('Table ' + model_table + ' exists; please use a different model table or drop ' + model_table + ' before calling this function.');

    # plpy.execute('drop table if exists ' + model_table);
    plpy.execute('create table ' + model_table + ' ( id text, weight float8, sv float8[] ) ifdef(`GREENPLUM', `distributed randomly')'); 

    plpy.execute('create temp table svm_temp_result ( id text, model MADLIB_SCHEMA.svm_model_rec ) ifdef(`GREENPLUM', `distributed randomly')');

    plpy.info("Parameters:");
    plpy.info(" * input_table = " + input_table);
    plpy.info(" * model_table = " + model_table);
    plpy.info(" * parallel = " + str(parallel));
    plpy.info(" * eta = " + str(eta));
    plpy.info(" * nu = " + str(nu));

    if (parallel) :
        # Learning multiple models in parallel  

        # Start learning process
        sql = 'insert into svm_temp_result (select \'' + model_table + '\' || gp_segment_id, MADLIB_SCHEMA.svm_nd_agg(ind,' + str(eta) + ',' + str(nu) + ') from ' + input_table + ' group by gp_segment_id)';
        plpy.execute(sql);

        # Store the models learned 
        numproc_t = plpy.execute('select count(distinct(gp_segment_id)) from ' + input_table);
        numproc = numproc_t[0]['count'];
        plpy.execute('select MADLIB_SCHEMA.svm_store_model(\'svm_temp_result\', \'' + model_table + '\',\'' + model_table + '\', ' + str(numproc) + ')');     

    else :
        # Learning a single model

        # Start learning process    
        sql = 'insert into svm_temp_result (select \'' + model_table + '\', MADLIB_SCHEMA.svm_nd_agg(ind,' + str(eta) + ',' + str(nu) + ') from ' + input_table + ')';
        plpy.execute(sql);

        # Store the model learned 
        plpy.execute('select MADLIB_SCHEMA.svm_store_model(\'svm_temp_result\', \'' + model_table + '\', \'' + model_table + '\')');

    # Retrieve and return the summary for each model learned    
    if parallel:
        where_cond = "position('" + model_table + "' in id) > 0 AND '" + model_table + "' <> id";
    else:
        where_cond = "id = '" + model_table + "'";

    summary = plpy.execute("select id, (model).inds, (model).rho, (model).nsvs from svm_temp_result where " + where_cond);

    result = [];
    for i in range(0,summary.nrows()):
        result = result + [(model_table, summary[i]['id'], summary[i]['inds'], summary[i]['rho'], summary[i]['nsvs'])];

    # Clean up the temp storage of models
    plpy.execute('drop table svm_temp_result');

    return result;

# ---------------------------------------------------
# Function to predict the labels of points in a table
# ---------------------------------------------------
def svm_predict( input_table, data_col, id_col, model_table, output_table, parallel):
    """
    Scores the data points stored in a table using a learned support vector model.

    @param input_table Name of table/view containing the data points to be scored
    @param data_col Name of column in input_table containing the data points
    @param id_col Name of column in input_table containing (integer) identifier for data point
    @param model_table Name under which we want to store the learned model 
    @param output_table Name of table to store the results 
    @param parallel A flag indicating whether the system should learn multiple models in parallel.
    
    """

    plpy.execute('drop table if exists ' + output_table);
    plpy.execute('create table ' + output_table + ' ( id int, prediction float8 )');

    if (parallel) :
        num_models_t = plpy.execute('SELECT COUNT(DISTINCT(id)) n FROM ' + model_table + ' WHERE position(\'' + model_table + '\' in id) > 0 AND \'' + model_table + '\' <> id;');
        num_models = num_models_t[0]['n'];

        sql = 'insert into ' + output_table + '(select t.' + id_col + ', sum(weight * MADLIB_SCHEMA.svm_kernel(m.sv, t.' + data_col + ')) / ' + str(num_models) + ' from ' + model_table + ' m, ' + input_table + ' t where position(\'' + model_table + '\' in m.id) > 0 AND \'' + model_table + '\' <> m.id group by 1)';
        plpy.execute(sql);

    else :
        sql = 'insert into ' + output_table + '(select t.' + id_col + ', sum(weight * MADLIB_SCHEMA.svm_kernel(m.sv, t.' + data_col + ')) from ' + model_table + ' m, ' + input_table + ' t where m.id = \'' + model_table + '\' group by 1)';
        plpy.execute(sql);

    return '''Finished processing data points in %s table; results are stored in %s table. 
           ''' % (input_table,output_table)

