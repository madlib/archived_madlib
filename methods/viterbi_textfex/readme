Method implemented: textfex_viterbi
Description:
Instead of extracting features on fly like many packages did, e.g., CRF PACKAGE,
we precomputed the features for all distinct tokens and use a factor table to store the  materialized factors.
When we do viterbi labeling to get the best label sequence, we only need to a single look up in the materialized 
factor tables. It is easy to imagine the benefits that our materialization can bring when we are 
labeling a large corpus. Our expermients also show that our implementation runs faster than the packages we know.
Our expermients show that our performance is 6ms/sentence in the context of part of speech tagging. The 6ms/sentece is 
amortized cost of feature extractions, get the best label sequence and the probabity of that best label sequence.

File included:
<madlib_root>/methods/viterbi_textfex/src/pg_gp/textfex.sql_in
Description: the code in this file is for feature extration. There are two functions
             implemented in this file. __textfex_feature_extraction is used  to extract
             the features for the whole training dataset. The function supports interactive mode and batch mode
<madlib_root>/methods/viterbi_textfex/src/pg_gp/viterbi_top1.c
Description: the code in this file is for calculating the top1 label sequence and the probability of that best label
             sequence.  the function implemented in this file are invoked by viterbi.sql_in.
<madlib_root>/methods/viterbi_textfex/src/pg_gp/viterbi.sql_in
Description: the code in this file is used for preparing the intermidaite tables for the viterbi c function.
<madlib_root>/methods/viterbi_textfex/src/pg_gp/test/textfex_viterbi.sql_in
Description: unit test code

Features implemented in our package:
EdgeFeatures:    These are transition features, solely dependent upon current label and previous 'y' values.
                 The feature encodes transition information and allows sequential information to be included in the model.
StartFeatures:   These features fire when the current label in consideration is a start state.
                 This feature checks whether the current label can be a start state or not, and fires accordingly.
EndFeatures:     These features fire when the current label in consideration is a end state.
                 This feature checks whether the current label can be a end state or not, and fires accordingly.
WordFeatures:    These features simply check whether the current token is present in the dictionary in the particular state 
                 under consideration or not. The dictionary is created on-the-fly from the training set.
UnknownFeatures: These features fire when the current token is not observed at the time of training.
RegexFeatures:   There features fire when the current token can be captured by the regular expressions.

How to use our textfex_viterbi:
1. Use CRF PACKAGE to generate the trained models. Basically CRF PACKAGE generates two model files feature and crf.
Wrte some simple scripts to convert the data in the model files to the data format required by our package.
2. invoke function madlib.__load_crf_model('/path/to/data') to create tables and import the data into tables.
3. invoke function madlib.__textfex_feature_extraction(args) to generate all the features
4. invoke function madlib.__vcrf_label(args) to get the best label sequence and the probability of that best sequence.
The test file also describes how we can use the pakcage.

Reference:
CRF PACKAGE: http://crf.sourceforge.net/introduction/features.html.
ViterbiCRF:  http://www.cs.berkeley.edu/~daisyw/ViterbiCRF.html
